{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55468e-d767-4a1d-99a8-c43e2515f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "## library import\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import shutil\n",
    "import xml.etree.ElementTree as et\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee8246-3c6d-44e9-9eb8-af7e59de9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## oxford_pet.zip이 보이는지 확인\n",
    "glob('oxford_pet.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150c29c-cfc4-44e7-94f7-40ce81faa7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 압축풀기\n",
    "if not os.path.exists('./oxford_pet'):\n",
    "  !unzip -q oxford_pet.zip -d oxford_pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623c6cd-185b-44b0-a73b-2a82d29d84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 압축이 풀린 directory 확인\n",
    "!ls oxford_pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085dd31-5f30-4420-8fe8-16f2eacd8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory 정보\n",
    "# os.path.join(): Builds a single path string by intelligently concatenating individual path components\n",
    "cur_dir = os.getcwd() # 현재 작업 디렉터리를 문자열로 가져온다\n",
    "data_dir = os.path.join(cur_dir, 'oxford_pet') # 현재 폴더 아래 oxford_pet라는 상위 데이터 폴더 경로를 만든다\n",
    "image_dir = os.path.join(data_dir, 'images')\n",
    "bbox_dir = os.path.join(data_dir, 'annotations', 'xmls')  \n",
    "seg_dir = os.path.join(data_dir, 'annotations', 'trimaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71653c-10bd-4b68-89d6-186b2af8d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data_dir:' ,data_dir)\n",
    "print('image_dir:' ,image_dir)\n",
    "print('bbox_dir:', bbox_dir)\n",
    "print('seg_dir:', seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7898a-449b-4ae8-b0a5-b1594688ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image file 수 확인\n",
    "image_files = [fname for fname in glob(image_dir +  '/*.jpg') if os.path.splitext(fname)[-1] == '.jpg']\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d86ee28-1b8d-43ee-a781-13a67047cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## localization을 위한 annotation이 되어 있는 file의 수 확인\n",
    "## 위의 이미지 갯수보다 annotation XML 파일 갯수가 적다. annotation XML 파일을 기준으로 해야함.\n",
    "\n",
    "bbox_files = [fname for fname in glob(bbox_dir +  '/*.xml') if os.path.splitext(fname)[-1] == '.xml']\n",
    "len(bbox_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27228d-4e3b-4e13-ac67-2aa56df54495",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 600 bbox와 매칭되는 이미지를 모우기 위한 새로운 폴더(new_images) 생성\n",
    "\n",
    "new_image_dir = os.path.join(data_dir, 'new_images')\n",
    "os.makedirs(new_image_dir, exist_ok=True)\n",
    "\n",
    "print('new_images:', new_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbff82c-c9d2-4c18-b60e-7974173fe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BB 정보를 가지고 있는 xml 파일 보기\n",
    "bbox_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0e71d-2425-444b-b707-869bae6a71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 600 bbox 리스트 읽어 bbox 이름과 같은 이미지를 new_images 폴더에 복사한다.\n",
    "# Metadata: Data about data\n",
    "# It supplies context such as who created a resource, when it was created, and how it should be used or interpreted\n",
    "\n",
    "for bbox_filename in bbox_files:\n",
    "  bbox_filename = bbox_filename.split('/')[-1]\n",
    "  # os.path.splitext(): Separates a path into two parts: the main file name and its extension\n",
    "  image_name = os.path.splitext(bbox_filename)[0]\n",
    "  image_file = image_dir + '/' + image_name + '.jpg'\n",
    "  # print(glob(image_file))\n",
    "  shutil.copy(image_file, new_image_dir)\n",
    "  # image_file: The source path-the file you want to duplicate\n",
    "  # new_iamge_dir: The destination; if it's a directory, the file is copied into that folder with the same file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64179eeb-c23e-4732-ad6a-3a1b705f1a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## new_images 폴더에 복사된 이미지 건수를 카운트한다.\n",
    "\n",
    "new_image_files = glob(new_image_dir + '/*')\n",
    "len(new_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd0651-2821-4575-8597-f47420dd13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 600개의 새로 복사된 이미지 리스트\n",
    "\n",
    "new_image_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6791d-e629-4db1-8e37-1287a84eed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataFrame 만들기\n",
    "\n",
    "pets_df = pd.DataFrame(new_image_files)\n",
    "pets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9654f4-dbf5-491b-a0e3-16efcbe5fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 컬럼명 입력\n",
    "\n",
    "pets_df.columns = ['full_path']\n",
    "pets_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63219574-108b-476a-8a10-70260ff2f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## full_path 컬럼에서 이미지 이름을 분리하여 file_name 컬럼명에 저장\n",
    "\n",
    "pets_df['file_name'] = pets_df['full_path'].str.split('/').str[-1]\n",
    "pets_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3b86e-8a55-43fe-8674-cfc2f811a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## file_name 컬럼에서 라벨 분리하여 label 컬럼에 저장\n",
    "# /d = any digit, + = repeat at least once\n",
    "\n",
    "pets_df['label'] = pets_df['file_name'].str.replace('_\\d+','').str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2bf27-00fa-420c-b1a3-589df7e04232",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 패스에서 레이블 분리 및 저장 확인\n",
    "pets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21d058-2883-4a18-a5bd-e538eca395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 파일명을 입력으로 받아, 같은 이름과 xml 확장자로 변경해서 리턴하는 함수\n",
    "\n",
    "def name_convert(col):\n",
    "  bbox_fname = bbox_dir + '/' + col.replace('jpg','xml')\n",
    "  return bbox_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554779b6-014f-439c-ac3b-f9f0da7b2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## name_convert 함수 호출해서 이미지 파일명과 같은 이름의 xml 확장자로 만든다.\n",
    "\n",
    "pets_df['bbox_full_path'] = pets_df['file_name'].apply(name_convert)\n",
    "pets_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bc81a-3f87-4291-96f7-af3d1ff5fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pets_df 데이터 구조 파악\n",
    "\n",
    "pets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03449fa-e8dd-412c-a9a2-f9f2190c1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## label 분포 확인\n",
    "## 각 class마다 200개 이미지 구성\n",
    "\n",
    "pets_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255d1d7-ad01-4467-8eba-cc8dab9d2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bbox_full_path 컬럼의 첫번째 데이터 가져오고 해당 내용 보기\n",
    "# .loc[row_index, column_name]\n",
    "\n",
    "sample_xml_file = pets_df.loc[0, 'bbox_full_path']\n",
    "print(sample_xml_file)\n",
    "\n",
    "# In Jupyter notebooks, placing an exclamation mark(!) before a line- like !ls-\n",
    "# runs that line as a shell command instead of Python code\n",
    "!cat {sample_xml_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9334f-13ab-4010-909c-51ee785390ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. xml Annotation 파일 읽어 이지미 크기와 Bounding box 위치을 파악\n",
    "## 2. xmin, ymin, xmax, ymax 형태를  x, y(중앙), w, h 형태로 변환하여 저장\n",
    "\n",
    "# ElementTree object stores the XML as a tree of Element nodes, where each node corresponds to a tag(e.g. <size> or <object>)\n",
    "\n",
    "def xml_annot_getxywh(xmlfile):\n",
    "  tree = et.parse(xmlfile)\n",
    "\n",
    "  width = float(tree.find('./size/width').text)\n",
    "  height = float(tree.find('./size/height').text)\n",
    "  xmin = float(tree.find('./object/bndbox/xmin').text)\n",
    "  ymin = float(tree.find('./object/bndbox/ymin').text)\n",
    "  xmax = float(tree.find('./object/bndbox/xmax').text)\n",
    "  ymax = float(tree.find('./object/bndbox/ymax').text)\n",
    "  xc = (xmin + xmax) / 2.\n",
    "  yc = (ymin + ymax) / 2.\n",
    "  x = xc / width\n",
    "  y = yc / height\n",
    "  w = (xmax - xmin) / width\n",
    "  h = (ymax - ymin) / height\n",
    "\n",
    "  return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8aba7-d5e0-49a4-b526-aa03afee9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 샘플 xml 파일에 대한 x, y, w, h 얻어오기\n",
    "\n",
    "xml_annot_getxywh(sample_xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da799452-a6ea-4fb4-adae-acfa900f4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd01f52-bab6-4641-aaca-8452f3ccf618",
   "metadata": {},
   "outputs": [],
   "source": [
    "## xml Annot 파일의 x, y, w, h 위치 정보를 가져와 DataFrame에 저장한다.\n",
    "\n",
    "pets_df['xywh'] = pets_df['bbox_full_path'].apply(xml_annot_getxywh)\n",
    "pets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc51be-748c-40c9-bdc6-f182efdd2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 튜플로 저장된 xywh 컬럼 값들을 하나씩 x, y, w, h 컬럼에 저장한다.\n",
    "\n",
    "pets_df['x'] = pets_df['xywh'].str[0]\n",
    "pets_df['y'] = pets_df['xywh'].str[1]\n",
    "pets_df['w'] = pets_df['xywh'].str[2]\n",
    "pets_df['h'] = pets_df['xywh'].str[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e777f99-0d3f-4722-b33a-415f7fdeff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4876e56-d17e-41ec-9132-a60b377bb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## label에 대한 라벨인코딩 수행\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "pets_df['label_conv'] = le.fit_transform(pets_df['label'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c322e5-12b1-4e70-a660-87df40b5e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3121271-8d43-4d31-ba07-efe99c36d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class와 idx 간의 변환\n",
    "\n",
    "class2idx = { label : idx for idx, label in enumerate(le.classes_) }\n",
    "idx2class = { idx :label for idx, label in enumerate(le.classes_) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad657916-2210-4856-80ef-3deffd288e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class2idx)\n",
    "print(idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0d7f6-aba6-46f0-8c54-43f8c5ebf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 패스 리스트 만들기\n",
    "\n",
    "images_list = pets_df['full_path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbfac2-e453-43a3-b6dc-db0119b456a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PIL 라이브러리 사용하여 이미지 파일 리스트에서 이미지 패스에 있는 이미지 읽고 리스트에 넣는다.\n",
    "## 이미지 resize로 맞추지 않으면 뒤쪽에서 Tensor에러 발생한다.\n",
    "\n",
    "x_image_list = []\n",
    "\n",
    "for fname in images_list:\n",
    "  image = Image.open(fname)\n",
    "  image = image.resize((224,224))\n",
    "  image = np.array(image)\n",
    "\n",
    "  x_image_list.append(image)\n",
    "\n",
    "x_image_list = np.array(x_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb36aec-8d74-4920-a3bf-c3ddcf98a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전체 이미지 리스트 형태 보기\n",
    "\n",
    "x_image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df5ed1-796b-4b6b-941c-e73fe69fe4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 라벨값과 bbox 위치값을 저장한다.\n",
    "\n",
    "y1_label = pets_df['label_conv'].values\n",
    "y2_xywh = pets_df[['x', 'y', 'w', 'h']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef362e5-3dfd-47af-b416-892328f2549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_label[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095d250-e0d2-408a-8e53-125fbb6fc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_xywh[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9dadba-bd20-4a8a-9e21-4911f0bf81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "\n",
    "IMG_SIZE = 224\n",
    "N_BBOX = len(x_image_list)\n",
    "N_TRAIN = 500\n",
    "N_VAL = N_BBOX - N_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44501ea7-41c8-44ca-99dc-a621a0b75e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annotation XML 파일 갯수로 리스트 만들고 Shuffle하고 500개 Train set과 100개 Valid set으로 나눈다.\n",
    "\n",
    "shuffle_list = list(range(N_BBOX))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbd071-c574-48e4-8394-cda89769856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train set idx 보기\n",
    "train_idx_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ab85b-156f-4433-80d3-45ed2efa5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train 데이터셋 만들기\n",
    "\n",
    "train_image_list = x_image_list[train_idx_list]\n",
    "train_y1_label = y1_label[train_idx_list]\n",
    "train_y2_xywh = y2_xywh[train_idx_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707cfa0-44f0-4ab4-b421-51515c249e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## valid 데이터셋 만들기\n",
    "\n",
    "valid_image_list = x_image_list[val_idx_list]\n",
    "valid_y1_label = y1_label[val_idx_list]\n",
    "valid_y2_xywh = y2_xywh[val_idx_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9ceb0-2dc2-4c28-99bf-2a7e064be5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_list.shape, valid_image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff5f9f-a6cb-4bc1-82da-bdf99625af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지와 X/Y/W/H 정보를 가지고 Train / Valid Dataset 만들기\n",
    "\n",
    "train_dataset_image = tf.data.Dataset.from_tensor_slices((train_image_list, train_y2_xywh))\n",
    "valid_dataset_image = tf.data.Dataset.from_tensor_slices((valid_image_list, valid_y2_xywh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e90cb9-8fad-46c0-8e0e-807a0a80b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices 읽어들인 이미지 리스트와 1개 y값들을 배치, 셔플한다.\n",
    "\n",
    "# train_dataset = train_dataset_image.batch(16).shuffle(1000).repeat()\n",
    "# valid_dataset = valid_dataset_image.batch(16).repeat()\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset_image.batch(16).shuffle(1000).cache().prefetch(AUTOTUNE)\n",
    "valid_dataset = valid_dataset_image.batch(16).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733fecc-d25b-4053-9034-27c698c4d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameters\n",
    "\n",
    "N_CLASS = len(class2idx)\n",
    "N_EPOCHS = 40\n",
    "N_BATCH = 16\n",
    "IMG_SIZE = 224\n",
    "learning_rate = 0.0001\n",
    "steps_per_epoch = N_TRAIN / N_BATCH\n",
    "validation_steps = int(np.ceil(N_VAL / N_BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695298e0-143c-4eae-8ff5-6f73cc736156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## valid_dataset에서 1개 가져와 분석해 보자\n",
    "## 이미지와 라벨로 받고 라벨은 다시 실제 라벨과 x,y,w,h 위치 값으로 나뉜다.\n",
    "\n",
    "for image, label in valid_dataset.take(1):\n",
    "  print(image.shape)\n",
    "  print(label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c16f9-0470-4116-a7dc-225e947259f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train dataset에서 1개의 image와 bbox를 읽어서 확인\n",
    "for image, label in valid_dataset.take(1):\n",
    "\n",
    "    ''' matplotlib Rectangle 이용하여 사각형 그릴 경우,\n",
    "    그림을 그리기 위해서 bbox의 왼쪽 아래 (xmin, ymin) 꼭지점 좌표를 계산하고,\n",
    "    xmin, ymin, w, h 각각을 image size에 맞게 scaling'''\n",
    "\n",
    "    # x, y(중앙), w, h 형태를 xmin, ymin, w, h 형태로 변환해야 함.\n",
    "\n",
    "    x = label[:,0]\n",
    "    y = label[:,1]\n",
    "    w = label[:,2]\n",
    "    h = label[:,3]\n",
    "    xmin = x[0].numpy() - w[0].numpy()/2.\n",
    "    ymin = y[0].numpy() - h[0].numpy()/2.\n",
    "    rect_x = int(xmin * IMG_SIZE)\n",
    "    rect_y = int(ymin * IMG_SIZE)\n",
    "    rect_w = int(w[0].numpy() * IMG_SIZE)\n",
    "    rect_h = int(h[0].numpy() * IMG_SIZE)\n",
    "\n",
    "    ## 그림 그리기\n",
    "    rect = Rectangle((rect_x, rect_y), rect_w, rect_h, fill=False, color='red')\n",
    "    plt.axes().add_patch(rect)\n",
    "    plt.imshow(image[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0b271-7548-4b29-bd21-4b6afca3a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential API를 사용하여 model 구성\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='SAME',\n",
    "                                  input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Dense(4, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9a24e-7924-41ea-b0a9-6a7b8446d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create model, compile & summary\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9904bd-479b-4e95-aadd-6160696070d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "  return tf.keras.losses.MeanSquaredError()(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab25328-1412-459c-b25f-bce3dfd9a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## learning rate scheduing\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps=steps_per_epoch*10,\n",
    "                                                          decay_rate=0.5,\n",
    "                                                          staircase=True)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['accuracy']) > loss='mse'로 간단하게 할수도 있음.\n",
    "# 여기서는 직접 loss function을 만들수 있음을 보여줌\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# metric: Additional statistic that Keras calculates after each batch and each epoch to tell you how well the model is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6127a-9b6d-4916-86ab-4d20a26d3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## callbacks : EarlyStopping, ModelCheckpoint\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('best_model_{val_loss:.2f}.h5', monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f2c40-f21f-42ef-af85-868db1186209",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train!\n",
    "model.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n",
    "         epochs=N_EPOCHS,\n",
    "         validation_data=valid_dataset,\n",
    "         validation_steps=validation_steps,\n",
    "         callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc7be4-7eba-417d-a7f9-8edb1d17d98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86999859-0a96-480f-a52c-827c3504f498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238633e0-5506-4d98-9428-a1dbf313f6cf",
   "metadata": {},
   "source": [
    "### Pretrained MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b3d24-e632-4139-a09b-97f3cfda0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce7dc9-fdff-41e1-aaed-b1761af52843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include_top: Tells Keras whether to load the network's original classification head\n",
    "mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df15096-edbe-40fe-ac38-24608e8b8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b3bee-7192-49d2-ab3a-ef4354c78d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mv_model():\n",
    "  model = models.Sequential()\n",
    "  model.add(mobilenetv2)\n",
    "  model.add(GlobalAveragePooling2D())\n",
    "  model.add(Dense(4, activation='sigmoid'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823cddb-ce37-4d7c-b72d-e1fa407d8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create model, compile & summary\n",
    "model = create_mv_model()\n",
    "\n",
    "## learning rate scheduing\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps=steps_per_epoch*5,\n",
    "                                                          decay_rate=0.5,\n",
    "                                                          staircase=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1f4ca-1f1c-410b-a3fc-ec7f11ce8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## callbacks : EarlyStopping, ModelCheckpoint\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('best_model_{val_loss:.2f}.h5', monitor='val_loss', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183c5ac-e269-4752-8f74-16ab33a8b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train!\n",
    "model.fit(train_dataset,\n",
    "         epochs=N_EPOCHS,\n",
    "         steps_per_epoch=steps_per_epoch,\n",
    "         validation_data=valid_dataset,\n",
    "         validation_steps=validation_steps,\n",
    "         callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02ee70-a6f1-481d-b880-21604d67419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 예측한 bounding box와 ground truth box를 image에 같이 표시\n",
    "## 정답은 빨간색 box, 예측은 파란색 box\n",
    "\n",
    "idx = 0\n",
    "num_imgs = validation_steps\n",
    "for val_data, val_gt in valid_dataset.take(num_imgs):\n",
    "    ## 정답 box 그리기 : 빨강박스\n",
    "    x = val_gt[:,0]\n",
    "    y = val_gt[:,1]\n",
    "    w = val_gt[:,2]\n",
    "    h = val_gt[:,3]\n",
    "    xmin = x[idx].numpy() - w[idx].numpy()/2.\n",
    "    ymin = y[idx].numpy() - h[idx].numpy()/2.\n",
    "    rect_x = int(xmin * IMG_SIZE)\n",
    "    rect_y = int(ymin * IMG_SIZE)\n",
    "    rect_w = int(w[idx].numpy() * IMG_SIZE)\n",
    "    rect_h = int(h[idx].numpy() * IMG_SIZE)\n",
    "\n",
    "    rect = Rectangle((rect_x, rect_y), rect_w, rect_h, fill=False, color='red')\n",
    "    plt.axes().add_patch(rect)\n",
    "\n",
    "    ## 예측 box 그리기 : 파랑박스\n",
    "    ## validation set에 대해서 bounding box 예측\n",
    "    prediction = model.predict(val_data)\n",
    "    pred_x = prediction[:,0]\n",
    "    pred_y = prediction[:,1]\n",
    "    pred_w = prediction[:,2]\n",
    "    pred_h = prediction[:,3]\n",
    "    pred_xmin = pred_x[idx] - pred_w[idx]/2.\n",
    "    pred_ymin = pred_y[idx] - pred_h[idx]/2.\n",
    "    pred_rect_x = int(pred_xmin * IMG_SIZE)\n",
    "    pred_rect_y = int(pred_ymin * IMG_SIZE)\n",
    "    pred_rect_w = int(pred_w[idx] * IMG_SIZE)\n",
    "    pred_rect_h = int(pred_h[idx] * IMG_SIZE)\n",
    "\n",
    "    pred_rect = Rectangle((pred_rect_x, pred_rect_y), pred_rect_w, pred_rect_h,\n",
    "                         fill=False, color='blue')\n",
    "    plt.axes().add_patch(pred_rect)\n",
    "\n",
    "    ## image와 bbox 함께 출력\n",
    "    plt.imshow(val_data[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7b929-18ad-4784-a430-f1dc92518e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7a9aa-d306-480c-b3c8-14e1be43bfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b86b33-540f-4c1b-9fe4-28fc2e8a8079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d57de-34c0-4d23-a6e5-eb32c13b8579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126568de-4fe2-4281-aa3e-36d628d91acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690f0a8-e491-45e3-8407-757fcad9ab3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
