{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8911f191-02bc-4689-bc96-ad988813554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977e1e1-ce71-4bb5-a846-e5be41ed3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드한 concrete_image.zip 파일 확인\n",
    "glob('concrete_image.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c92b4-f15e-44f6-9a0e-edce64bf0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더 생성 및 concrete_image.zip 파일 압축 풀기\n",
    "\n",
    "if not os.path.exists('IMAGE'):\n",
    "    os.mkdir('IMAGE')\n",
    "    !unzip concrete_image.zip -d IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714615a-c4ac-4c7e-8ef4-37e1d9653c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete_image Negative 폴더 안의 이지미 갯수\n",
    "!ls -l ./IMAGE/Negative/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c636c1-10d5-403e-8bdb-e92a656c8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete_image Positive 폴더 안의 이지미 갯수\n",
    "!ls -l ./IMAGE/Positive/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f7acb0-03ed-407f-9a13-cb0ad07d7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 패스 지정\n",
    "path = './IMAGE/Negative/00001.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858d99f-9ea0-472a-b90f-a1ea98c5abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽어오기\n",
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89495376-6e3a-4fd5-b53a-8708bc2a2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 shape 확인\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff512d70-923e-466c-a901-acb35251cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어온 Negative 이미지 보기\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcaa58-0a6e-4023-b993-28e537004a9d",
   "metadata": {},
   "source": [
    "- ImageDataGenerator 와 flow_from_directory 이용하여 이미지 데이터셋 생성, 라벨링(라벨인코딩,원핫인코딩) 한꺼번에 처리 할수 있다.\n",
    "- [조건] IMAGE 폴더 있고 그 아래 각 class별 이름 폴더가 있고 class별 폴더 안에 이미지 파일 있을 경우, 아래 수행합니다.</font>\n",
    "- class 폴더 이름을 label로 취급\n",
    "- 이미지 읽어 메모리 올리기\n",
    "- 이미지 데이터 Augmentation 가능\n",
    "- class 폴더 이름 label을 One-Hot-Encoding 수행\n",
    "- 이미지, 라벨 튜플 묶고, shuffle, batch 후 데이터셋 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca158b-dbb2-4af6-9475-bb39d7cd3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tunning\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (227, 227, 3)  # 사이즈 확인\n",
    "num_classes = 2    # Postive , Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3ee19-9e1c-490a-b675-a133ad018705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 증강 시킬때 사용하는 ImageDataGenerator 함수 import\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f0d6c-e539-44f0-8e78-1fb0ec7e760f",
   "metadata": {},
   "source": [
    "##### ImageDataGenerator 와  flow_from_directory 기능\n",
    "+ ImageDataGenerator : 이미지 데이터에 대해 증강(augmentation)과 rescaling, validation_split 등의 전처리 기능 수행\n",
    "+ flow_from_directory : 실제 이미지 데이터 읽고 배치, 셔플하고 labeling 수행 및 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271cb21-10f9-444c-822d-7451bf47377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator 이용하여 이미지 증강과 전처리하기\n",
    "# - 여기서는 data augmentation 하지 않음 : 주석처리했으며 필요하면 주석해체하여 사용하면 됨\n",
    "# - 1개 IMAGE 폴더로 Train, Test dataset으로 나누어야 되므로 validation_split 사용해야 함\n",
    "# - validation 데이터 사이즈 입력 : validation_split=0.2 --> train set : valid set = 8 : 2\n",
    "# - rescaling 수행\n",
    "\n",
    "image_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255,\n",
    "      validation_split=0.2     # train set : valid set = 8 : 2\n",
    "#       rotation_range=30,\n",
    "#       width_shift_range=0.1,\n",
    "#       height_shift_range=0.1,\n",
    "#       shear_range=0.1,\n",
    "#       zoom_range=0.1,\n",
    "#       horizontal_flip=True,\n",
    "#       fill_mode='nearest'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba69c1b-9506-450c-9481-50223e9581bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator.flow_from_directory\n",
    "# - 이미지 폴더 내의 데이터  읽고 배치 , 셔플하고 labeling 수행\n",
    "# - 2개 Class에 대한 라벨링(라벨인코딩,원핫인코딩) 수행\n",
    "# - subset = 'training' --> training_generator 생성\n",
    "# - subset = 'validation' --> test_generator 생성\n",
    "# - 수행결과, IMAGE 폴더로 Train 4,800건, Test 1,200건 dataset 만듬\n",
    "\n",
    "# IMAGE 포더 밑에 .ipynb_checkpoints 폴더 있을경우 폴데 삭제\n",
    "!rm -rf ./IMAGE/.ipynb_checkpoints\n",
    "\n",
    "# categorical: Returns a one-hot encoded vector whose length equals the number of classes found\n",
    "# Practical rule: Choose binary for a two-class sigmoid model\n",
    "# Choose categorical for three or more classes-or for two classes when you prefer softmax and one-hot targets\n",
    "training_generator = image_datagen.flow_from_directory(\n",
    "    './IMAGE',\n",
    "    batch_size=batch_size,        # batch_size = 32\n",
    "    target_size=(227, 227),       # 원하는 출력 사이즈 입력. 데이터 생성후 (227, 227, 3) 변환. 디폴트 color_mode='rgb', 3 채널\n",
    "    class_mode = 'categorical',   # binary 혹은 categorical\n",
    "    shuffle = True,\n",
    "    subset = 'training'           # training 혹은 validation. ImageDataGenerator의 validation_split 사용하므로 subset 지정해야\n",
    "    )\n",
    "\n",
    "test_generator = image_datagen.flow_from_directory(\n",
    "    './IMAGE',\n",
    "    batch_size=batch_size,\n",
    "    target_size=(227, 227),       # 원하는 출력 사이즈 입력. 데이터 생성후 (227, 227, 3) 변환. 디폴트 color_mode='rgb', 3 채널\n",
    "    class_mode = 'categorical',   # binary 혹은 categorical\n",
    "    shuffle = False,\n",
    "    subset = 'validation'         # training 혹은 validation. ImageDataGenerator의 validation_split 사용하므로 subset 지정해야\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfb95c-52a9-472f-87e0-8eafaa127c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test 건수 확인\n",
    "# batch_size : 32\n",
    "len(training_generator) * batch_size , len(test_generator) * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7b6a9-37e5-4b2d-a25a-b77e7d287507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 이름 및 번호 매핑 확인\n",
    "print(training_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55ee25-2347-4b1e-8ebc-22c81458850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋에서 1개 가져오기\n",
    "batch_img, batch_label = next(iter(training_generator))\n",
    "print(batch_img.shape)    # 32개의 사진 이미지\n",
    "print(batch_label.shape)  # 32개의 사진에 대한 원핫인코딩된 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f7a98-8bcf-426d-9db1-4d4a06bfad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True Value : ', batch_label[0])  # 32개의 사진 이미지중 첫번째 사진의 라벨\n",
    "plt.imshow(batch_img[0])   # 32개의 사진 이미지중 첫번째 사진 이미지\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad498df4-ba94-4ba9-9109-aa7d29aed1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API 모델 정의\n",
    "\n",
    "inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "net = tf.keras.layers.Conv2D(32, (3, 3), padding='SAME')(inputs)  # 227 X 227 X 32\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.Conv2D(32, (3, 3), padding='SAME')(net)  # 227 X 227 X 32\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(net)  # 113 X 113 X 32\n",
    "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(net)  # 113 X 113 X 64\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(net)  # 113 X 113 X 64\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(net)  # 56 X 56 X 64\n",
    "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = tf.keras.layers.Flatten()(net)  # 200,704\n",
    "net = tf.keras.layers.Dense(512)(net)\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "net = tf.keras.layers.Dense(num_classes)(net)\n",
    "net = tf.keras.layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8f5a7-7f11-4567-96cb-26f21a425cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='categorical_crossentropy',  # Loss Function\n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33e3b3-2115-43d9-a654-a996f320bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac50fd-ff10-4caa-a806-b57eecf5a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback : EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# ModelCheckpoint\n",
    "checkpoint_path = \"my_checkpoint.ckpt\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1)\n",
    "\n",
    "# ReduceLROnPlateau : val_loss가 2번 이상 감소되지 않으면 lr * factor = lr 새로운 lr로 변경해서 학습 진행\n",
    "lrReducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823dd98-aed6-4391-87cc-8a3912ab169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator 와 flow_from_directory 이용하여 데이터 만들었을때 아래와 같이 학습\n",
    "# val_accuracy 50% 정도 나옴\n",
    "# num_epochs = 10\n",
    "# batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data = test_generator,\n",
    "    epochs=10,\n",
    "    batch_size = batch_size,\n",
    "    callbacks=[es, checkpoint, lrReducer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a2895-0380-4c68-8113-7843cfa4ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc9a65-5d52-4fba-b151-97ee1db158a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 그래프\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9474c94-6e25-4fc6-8672-cae00cb83ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator 샘플 데이터 가져오기\n",
    "# 배치 사이즈 32 확인\n",
    "batch_img, batch_label = next(iter(test_generator))\n",
    "print(batch_img.shape)\n",
    "print(batch_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9db32-3fb4-4f87-a201-4eba102f9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32개 Test 샘플 이미지 그려보고 예측해 보기\n",
    "\n",
    "i = 1\n",
    "plt.figure(figsize=(16, 30))\n",
    "for img, label in list(zip(batch_img, batch_label)):\n",
    "    pred = model.predict(img.reshape(-1,227,227,3))\n",
    "    pred_t = np.argmax(pred)\n",
    "    plt.subplot(8, 4, i)\n",
    "    plt.title(f'True Value:{np.argmax(label)}, Pred Value: {pred_t}')\n",
    "    plt.imshow(img)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf9922-c050-4efb-8c1f-f38d16ccc45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40b3ce-a2cc-45a0-9564-4c84681cd002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b13d91-d5b0-4554-af08-d10b57c692d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398aab05-3f92-4b40-b5ea-31ef10d04dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
