{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a63387-1779-41b5-bd45-0d56a1a6c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51de60f-bab2-4831-9a82-68f14db83191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드한 concrete_image.zip 파일 확인\n",
    "glob('concrete_image.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f44f8-68f5-449f-932c-04ca4285fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더 있는지 확인\n",
    "if not os.path.exists('IMAGE'):\n",
    "    os.mkdir('IMAGE')\n",
    "\n",
    "    # concrete_image.zip 압축풀기 : 4분 소요\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('concrete_image.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('IMAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49d5bf-ddcd-40ca-85c1-995d38d37c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete_image Negative 폴더 안의 이지미 갯수\n",
    "!ls -l ./IMAGE/Negative/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596aa1ba-b910-4fa7-9453-28d0ae429b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete_image Positive 폴더 안의 이지미 갯수\n",
    "!ls -l ./IMAGE/Positive/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c612984-8b77-458d-9063-071555ef6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 패스 지정\n",
    "path = './IMAGE/Negative/00001.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4ec40-bede-45db-afa0-1b7d92a84c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽어오기\n",
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac2178-230e-42ce-9b7d-898e8dd4c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 shape 확인\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00120bd2-95ce-4e7c-8dfe-225e71cfd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어온 Negative 이미지 보기\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67be6e-aa5b-48f6-9ab1-e89ac09749e2",
   "metadata": {},
   "source": [
    "- ImageDataGenerator 와 flow_from_directory 이용하여 이미지 데이터셋 생성, 라벨링(라벨인코딩,원핫인코딩) 한꺼번에 처리 할수 있다.\n",
    "- [조건] IMAGE 폴더 있고 그 아래 각 class별 이름 폴더가 있고 class별 폴더 안에 이미지 파일 있을 경우, 아래 수행합니다.</font>\n",
    "\n",
    "- class 폴더 이름을 label로 취급\n",
    "- 이미지 읽어 메모리 올리기\n",
    "- flow_from_directory 함수에서 이미지 사이즈 변경 : 227,227 --> 224,224 > MobileNetV2은 [96, 128, 160, 192, 224] 사이즈만 지원\n",
    "- class 폴더 이름 label을 One-Hot-Encoding 수행\n",
    "- 이미지, 라벨 튜플 묶고, shuffle, batch 후 데이터셋 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d1619-9a36-45bd-b5f8-fed24e7af725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tunning\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size =32\n",
    "\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (224, 224, 3)  # 사이즈 확인\n",
    "num_classes = 2    # Postive , Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11859580-a205-49ad-bdf5-226937a455ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875714d-ca24-420a-9f60-1b0383fec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator 이용하여 이미지 증강과 전처리하기\n",
    "# - 여기서는 data augmentation 하지 않음 : 주석처리했으며 필요하면 주석해체하여 사용하면 됨\n",
    "# - 1개 IMAGE 폴더로 Train, Test dataset으로 나누어야 되므로 validation_split 사용해야 함\n",
    "# - validation 데이터 사이즈 입력 : validation_split=0.2 --> train set : valid set = 8 : 2\n",
    "# - (주의점) MobileNetV2에 인풋으로 사용하기 전에 전 처리하는 코드가 preprocess_input으로 함수화 되어 있습니다. 따라서 그대로 사용하시면 됩니다.\n",
    "# - 그래서 rescale 수행하지 않음\n",
    "\n",
    "image_datagen = ImageDataGenerator(\n",
    "      #rescale=1. / 255,        # MobileNetV2 경우, 아래 preprocess_input 호출해서 리스케일 하므로 커멘트 처리함\n",
    "      validation_split=0.2,     # train set : valid set = 8 : 2\n",
    "      preprocessing_function = preprocess_input  # MobileNetV2 사용한다면 전처리 코드를 넣어 주면 됩니다.\n",
    "#       rotation_range=30,\n",
    "#       width_shift_range=0.1,\n",
    "#       height_shift_range=0.1,\n",
    "#       shear_range=0.1,\n",
    "#       zoom_range=0.1,\n",
    "#       horizontal_flip=True,\n",
    "#       fill_mode='nearest'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895766b-b944-40a1-a409-e330b1956bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator.flow_from_directory\n",
    "# - 이미지 폴더 내의 데이터  읽고 배치 , 셔플하고 labeling 수행\n",
    "# - 2개 Class에 대한 라벨링(라벨인코딩,원핫인코딩) 수행\n",
    "# - MobileNetV2은 [96, 128, 160, 192, 224] 사이즈만 지원하므로 flow_from_directory 함수에서 사이즈 변경함\n",
    "# - subset = 'training' --> training_generator 생성\n",
    "# - subset = 'validation' --> test_generator 생성\n",
    "# - 수행결과, IMAGE 폴더로 Train 4,800건, Test 1,200건 dataset 만듬\n",
    "\n",
    "# IMAGE 포더 밑에 .ipynb_checkpoints 폴더 있을경우 폴데 삭제\n",
    "!rm -rf ./IMAGE/.ipynb_checkpoints\n",
    "\n",
    "training_generator = image_datagen.flow_from_directory(\n",
    "    './IMAGE',\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224, 224),       # 원하는 출력 사이즈 입력. MobileNetV2 위해 사이즈 변경 : 227,227 --> 224,224. 최종 출력 : (224,224,3)\n",
    "    class_mode = 'categorical',   # binary , categorical\n",
    "    shuffle = True,\n",
    "    subset = 'training'           # training, validation. ImageDataGenerator의 validation_split 사용하므로 subset 지정\n",
    "    )\n",
    "\n",
    "test_generator = image_datagen.flow_from_directory(\n",
    "    './IMAGE',\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224, 224),       # 원하는 출력 사이즈 입력. MobileNetV2 위해 사이즈 변경 : 227,227 --> 224,224. 최종 출력 : (224,224,3)\n",
    "    class_mode = 'categorical',   # binary , categorical\n",
    "    shuffle = False,\n",
    "    subset = 'validation'         # training, validation. ImageDataGenerator의 validation_split 사용하므로 subset 지정\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ad3f3-4ea9-4629-a358-611624ffe790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test 건수 확인\n",
    "len(training_generator) * 32 , len(test_generator) * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37619e4b-762a-4a15-86d5-e9315107dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 이름 및 번호 매핑 확인\n",
    "print(training_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c800d-d210-4910-8ecb-effec415ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_img, batch_label = next(iter(training_generator))\n",
    "\n",
    "print('True Value : ', batch_label[0])  # 32개의 사진 이미지중 첫번째 사진의 라벨\n",
    "plt.imshow(batch_img[0])   # 32개의 사진 이미지중 첫번째 사진 이미지\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66ce35-42d6-40cc-9a8e-e1ebc32ae1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 applicatioins에 어떤 종류의 모델 있는지 확인\n",
    "dir(tf.keras.applications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696e364-6316-4521-9388-08d6883ad4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 모델 MobileNet V2에서 기본 모델을 생성합니다.\n",
    "# 아래와 같은 형식을 Transfer Learning 사용하며 됩니다. 우리는 그냥 불러다 사용할줄 알면 됩니다.\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbc505-b3c0-405e-bc1c-f9f9c0081b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22bb868-6126-41fa-af23-147bfb07dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet V2 베이스 모델의 파라미터를 학습하지 않도록 고정하기\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466ec28-b65b-40ab-a48d-a540521d5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning 과 Fine Tuning 으로 모델 구축\n",
    "# - GlobalAveragePooling2D 레이어 : 2D 입력 텐서의 공간 차원을 평균화하여 하나의 벡터로 변환합니다. 즉, 7 X 7 를 Average pooling해서 1개 벡터 변환\n",
    "# - 이 레이어는 입력의 공간 위치를 무시하고, 전체적인 패턴을 파악 도움이 되며, 모델의 파라미터 수를 크게 줄일수 있음\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)  # 3차원(7, 7, 1280) --> 1차원(1280)으로 줄이기 --> Dense 입력 할수 있게 된다.\n",
    "output = tf.keras.layers.Dense(2, activation='softmax')(x)  # Fine Tuning\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddda1c-e6bd-46db-97e7-0b4e365c6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='categorical_crossentropy',  # Loss Function\n",
    "              metrics=['accuracy'])             # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fb924-39b4-49e4-a432-ba005b23bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# ModelCheckpoint\n",
    "checkpoint_path = \"my_checkpoint.ckpt\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1)\n",
    "\n",
    "# ReduceLROnPlateau : val_loss가 2번 이상 감소되지 않으면 lr * factor = lr 새로운 lr로 변경해서 학습 진행\n",
    "lrReducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffdc51-21b3-471e-b3a2-56b940946290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator 와 flow_from_directory 이용하여 DataSet을 만들었으며\n",
    "# num_epochs = 10\n",
    "# batch_size = 32\n",
    "# 앞쪽의 CNN 모델과 Transfer Learning 모델과 비교하면 엄청난 성능차이를 알수 있음.(첫 epoch에 val_accuracy 98% 성능 보임)\n",
    "\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data = test_generator,\n",
    "    epochs=5,\n",
    "    batch_size = batch_size,\n",
    "    callbacks=[es, checkpoint, lrReducer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ab699-9a2b-4a81-ba93-bd809cbfa28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c200d-0037-477d-bbdf-9a48ce6c4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 그래프\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70e8fa-75b4-4997-aeca-03f1a4119876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generator 샘플 데이터 가져오기\n",
    "# 배치 사이즈 32 확인\n",
    "\n",
    "batch_img, batch_label = next(iter(test_generator))\n",
    "print(batch_img.shape)\n",
    "print(batch_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33408423-fd6c-407a-a926-b2fa0b316871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 rescale 되어 있는 상태\n",
    "batch_img[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5505a8-0810-417a-b102-7e4cdfe75b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% 성능 보여줌\n",
    "\n",
    "i = 1\n",
    "plt.figure(figsize=(16, 30))\n",
    "for img, label in list(zip(batch_img, batch_label)):\n",
    "    pred = model.predict(img.reshape(-1, 224,224,3))\n",
    "    pred_t = np.argmax(pred)\n",
    "    plt.subplot(8, 4, i)\n",
    "    plt.title(f'True Value:{np.argmax(label)}, Pred Value: {pred_t}')\n",
    "    plt.imshow(img)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae503aa7-8ef3-4cfb-a302-f3363982eff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a58ebb-943f-4c72-97ac-8d5e329ee9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a54c3-a578-47b4-accc-eead76760846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21b11c-e1e6-49b0-8db6-298a7db8f8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f3409-f67b-40ce-9889-4aec7b83e809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
