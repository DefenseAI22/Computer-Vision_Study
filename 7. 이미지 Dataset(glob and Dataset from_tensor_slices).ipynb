{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a78ebe5-9b73-42a5-b4d3-bed6acddfbfd",
   "metadata": {},
   "source": [
    "### 이미지 데이터셋 만들기(라벨 정보 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c7a6d0-a8f9-4ac1-b86a-386bc332efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b02f9f-95df-494d-87a4-108640751378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업로드 concrete_image.zip 파일 확인\n",
    "# The function returns a list of all files in the current working directory that match pattern\n",
    "glob('concrete_image.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc0ebc82-9f43-4061-92a9-d1764f5463da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open concrete_image.zip, concrete_image.zip.zip or concrete_image.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 폴더 생성 및 concrete_image.zip 파일 압축 풀기 > 3,000개 이미지로 실습을 위해 데이터 축소\n",
    "\n",
    "if not os.path.exists('IMAGE'):\n",
    "    os.mkdir('IMAGE')\n",
    "    !unzip concrete_image.zip -d IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ac108-b53a-4b33-a441-5663cf175bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete_image Negative 폴더 안의 이미지 갯수\n",
    "!ls -l ./IMAGE/Negative/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65284385-0f47-4585-a547-a2970ee9023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete_image Positive 폴더 안의 이미지 갯수\n",
    "!ls -l ./IMAGE/Positive/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17316da-654d-43ad-863f-573647551b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 패스 지정\n",
    "path = './IMAGE/Negative/00001.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47936cbd-d0ec-432f-a6bd-8a091abfbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 읽어오기\n",
    "# Reads the entire file at the given path as a binary string tensor\n",
    "# Binary data: Information encoded purely as sequences of bits-zeros and ones-that a computer can process directly\n",
    "# Byte: Fundamental unit of digital storage that consists of exactly eight bits\n",
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21387ec6-a13d-4787-bc6d-a7ee5de5fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 shape 확인\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ceea2-e589-415a-bdcc-e94ab231b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어온 이미지 보기\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c191a7-4f60-4640-89bd-6f4709e31273",
   "metadata": {},
   "source": [
    "### glob과 from_tensor_slices , Pipeline 이용하여 이미지 데이터셋 만들기\n",
    "+ glob활용하여 이미지 패스를 리스트 형태로 만들기\n",
    "+ from_tensor_slices 활용하여 이미지 패스 리스트를 Dataset 으로 만들기\n",
    "+ Pipeline 이용하여 map, cache, Shuffle, batch, prefetch 된 Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d2543-6bd4-4b48-ab30-2b226a70a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob 활용하여 이미지 패스를 만든다.\n",
    "# glob 결과로 리스트를 리턴\n",
    "\n",
    "image_paths = glob('./IMAGE/*/*.jpg')\n",
    "\n",
    "print(len(image_paths))\n",
    "print(image_paths[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bdb49-a413-4f0e-b47b-fba04cf4daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 패스를 주면 이미지 읽고 반환하는 함수\n",
    "\n",
    "def read_image(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e61fd-23ae-4ee0-81c7-ede94fc863c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병렬화\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1571b-6c5a-47ca-9826-c0c6745a561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 패스 리스트를 from_tensor_slices 사용하여 데이터셋을 만들고\n",
    "# map 함수를 사용하여 각 이미지 패스의 이미지들을 병렬로 읽어오기\n",
    "\n",
    "# tf.data.Dataset.from_tensor_slices: Converts a tensor-like object into a tf.data.Dataset, where each element is a slice (row) of the input\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "dataset = dataset.map(read_image, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a077c-78d9-41cd-b410-0258883bf79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋에서 1개 이미지 가져오기\n",
    "tf_image = next(iter(dataset))\n",
    "tf_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b94c9-478c-448e-8cf3-53f54bf5c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative 데이터 샘플\n",
    "\n",
    "plt.imshow(tf_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad90ed1-6fa6-43be-aef3-4f638264582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 패스의 이미지 읽고(map) 4개 batch 묶기\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "dataset = dataset.map(read_image)\n",
    "dataset = dataset.batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c572d0-c7fd-4656-bb38-d3fd56c73d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 mini-batch 가져오기\n",
    "tf_images = next(iter(dataset))\n",
    "tf_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1b09a-b345-46f8-87df-9211e27e5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative 데이터 샘플들\n",
    "\n",
    "for i in range(4):\n",
    "    plt.imshow(tf_images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de82ae2-b4ba-4494-9fba-e570bd4ca471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices > map > cache > batch > shuffle > prefetch 형태로 사용\n",
    "\n",
    "# This converts the Python list image_paths into a tf.data.Dataset, where each element is a single file path string\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_paths)  # 입력 : 이미지 패스 리스트\n",
    "# map applies your custom read_image function to every element, turning each file path into an actual image tensor\n",
    "dataset = dataset.map(read_image, num_parallel_calls=AUTOTUNE) # 이미지 패스의 각 이미지 읽기\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.batch(4)\n",
    "dataset = dataset.shuffle(buffer_size=512)\n",
    "dataset = dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed149669-7e9b-484c-be7c-1064ca38beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle 시간 좀 걸림\n",
    "tf_images = next(iter(dataset))\n",
    "tf_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92bbf4-1a72-4fb8-9a2f-6e88a6766e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle 이전에 첫번째 이미지와 지금은 다른 이미지로 shuffle 되는 것 확인\n",
    "plt.imshow(tf_images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0bd53-cf6d-4c61-8850-66b1ccf9bf41",
   "metadata": {},
   "source": [
    "### Data Preprocess\n",
    "1. glob 이용하여 이미지 패스 읽기\n",
    "2. shuffle\n",
    "3. Train/Test 비율로 나누기\n",
    "4. 이미지 라벨링 만들기\n",
    "5. from_tensor_slices > map > cache > batch > shuffle > prefetch 파이프라인 사용하여 이미지/라벨링 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac7f20-ef1c-4bd7-b2dd-1073093a7329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tunning\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (227, 227, 3)  # 사이즈 확인\n",
    "num_classes = 2              # Postive , Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f396c43-7a81-4eb4-a49f-9d1330f30d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob를 통해 이미지 패스 읽어오기\n",
    "image_paths_list = glob('./IMAGE/*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb3a43-c543-4af7-916d-aa764cfb1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 섞어 주기\n",
    "image_paths = np.random.permutation(image_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33796b-d4ad-45d5-b518-a141ea6bd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 이미지 패스 보기\n",
    "image_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51d52b-0a00-4366-ab28-23feb670e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8: 2 비율로 Train, Test 이미지셋 나누기\n",
    "\n",
    "TRAIN_SIZE = int(len(image_paths) * 0.8) # 4,800\n",
    "train_paths = image_paths[:TRAIN_SIZE]\n",
    "test_paths = image_paths[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7595e-adeb-405b-83cb-a5e4c83d26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ddbdd-14b1-4966-97b7-5b07193bf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive, Negative 폴더 이름 반환하는 함수\n",
    "# EX) ./IMAGE/Negative/07269.jpg --> Negative 가져오는 함수 만들기\n",
    "\n",
    "def get_class_name(path):\n",
    "    name = os.path.dirname(path).split('/')[-1]  # 폴더명\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3010965-e9ec-4cce-a212-2acde970d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_class_name 함수 정상 동작 여부 확인\n",
    "\n",
    "for path in train_paths[:4]:\n",
    "  print(path, get_class_name(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6018bff1-c38f-45c8-bbba-7194b79e170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 이름 만들기\n",
    "# np.unique(): Returns the sorted array of distinct values found in the input array\n",
    "# array: An ordered collection of elements that are stored consecutively in memory\n",
    "# and accessed by a numeric index starting at zero\n",
    "\n",
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e45cd2-4c66-452d-857b-70e6aa976e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩 간단 변환 예제\n",
    "print( 'Negative' == np.array(['Negative', 'Positive']) )\n",
    "print( ('Negative' == np.array(['Negative', 'Positive'])).astype(int) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea8969-42e2-4729-847e-3acbbcea639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 패스에서 'Negative', 'Positive' 폴더부분을 읽고\n",
    "# class_name과 비교해서(numpy broadcasting) onehot 만들어 리턴\n",
    "# tf.cast(x, dtype): Converts a TensorFlow tensor x to the data type specified by dtype\n",
    "\n",
    "def get_label(path):\n",
    "    label_name = tf.strings.split(path, '/')[-2]\n",
    "    onehot = tf.cast(label_name == class_names, tf.uint8)   # One-Hot-Encoding\n",
    "    # return tf.argmax(onehot)                         # 이번에는 onehot이 아닌 label 번호로\n",
    "    return onehot                                      # 이번에는 onehot으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd408d37-e502-4540-967d-5faabe1350e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된 패스의 이미지를 읽고 rescale하고 , 원핫 인코딩된 class 라벨을 만들어 이미지와 라벨을 리턴\n",
    "\n",
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "\n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b68184-4e0b-464d-bbd0-8aa29761b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 변환 처리 : 여기서는 사용하지 않음\n",
    "\n",
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814cfb8-b3f0-49dc-b968-2ac9f6e0984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_image_label 함수 잘 동작하는지 확인\n",
    "load_image_label('./IMAGE/Negative/00472.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020b10e-665d-4b24-8222-3825f19c854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병렬화\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa35b1-76dc-4db6-b625-6348705146b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices > map > cache > batch > shuffle > prefetch 형태로 사용\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths) # 4800\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "#train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=512)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05008fd-17fe-45ca-8249-9d1d95413a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices > map > cache > batch > prefetch 형태로 사용\n",
    "# test set은 shuffle 하지 않음\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.cache()\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210fd57-8a7a-45e9-b606-a6f42bc65f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 이미지 확인\n",
    "\n",
    "i = 0\n",
    "for batch_img, batch_label in train_dataset.take(1):\n",
    "  if i == 0 :\n",
    "    print(batch_img[i].shape)\n",
    "    plt.imshow(batch_img[i])\n",
    "  i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d7e3c-21c8-4b4c-a609-eecaacbcc086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API 모델 정의\n",
    "\n",
    "inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "net = tf.keras.layers.Conv2D(32, (3, 3), padding='SAME')(inputs)  # 227 X 227 X 32\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.Conv2D(32, (3, 3), padding='SAME')(net)  # 227 X 227 X 32\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(net)  # 113 X 113 X 32\n",
    "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(net)  # 113 X 113 X 64\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(net)  # 113 X 113 X 64\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(net)  # 56 X 56 X 64\n",
    "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = tf.keras.layers.Flatten()(net)  # 200,704\n",
    "net = tf.keras.layers.Dense(512)(net)\n",
    "net = tf.keras.layers.Activation('relu')(net)\n",
    "net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "net = tf.keras.layers.Dense(num_classes)(net)\n",
    "net = tf.keras.layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300531c-206e-4b20-a5c9-a3bf6d99ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='categorical_crossentropy',  # Loss Function\n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5f20c-3a0e-43bb-92ac-ec03dbb32e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback : EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "# ModelCheckpoint\n",
    "checkpoint_path = \"my_checkpoint.ckpt\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1)\n",
    "\n",
    "# ReduceLROnPlateau : val_loss가 2번 이상 감소되지 않으면 lr * factor = lr 새로운 lr로 변경해서 학습 진행\n",
    "lrReducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6519a6-715b-41f6-b87d-a0440238e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "# batch_size = 32\n",
    "# 데이터 학습시간 오래 걸려, take(10) 사용함 : 정확도 50% 안됨\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset.take(10),\n",
    "    validation_data=(test_dataset.take(10)),\n",
    "    epochs=5,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[es, checkpoint, lrReducer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389eeb7-5c70-46d4-aa99-84ec00c7602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb0d67-3638-4a7c-8f88-00e4fad92333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00233b2-0478-4f46-ba84-335b892d8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 너무 적은 데이터로 학습하니 성능이 50% 정도 나옴\n",
    "\n",
    "plt.figure(figsize=(16, 30))\n",
    "for batch_img, batch_label in test_dataset.take(1):\n",
    "    for i in range(len(batch_img)):\n",
    "        pred = model.predict(batch_img[i].numpy().reshape(-1,227, 227, 3))\n",
    "        pred_t = np.argmax(pred)\n",
    "        plt.subplot(8, 4, i+1)\n",
    "        plt.title(f'True Value:{np.argmax(batch_label[i])}, Pred Value: {pred_t}')\n",
    "        plt.imshow(batch_img[i])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34593ff1-500e-4974-91e6-a8dec6a43dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
